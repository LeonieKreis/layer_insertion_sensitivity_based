{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for running single training and compare them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and set seed optionally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "\n",
    "from layer_insertion_loop import layer_insertion_loop\n",
    "from train_and_test_ import train, check_testerror\n",
    "from nets import feed_forward, two_weight_resnet\n",
    "from utils import ema\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "torch.set_num_threads(8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and list hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_width = 100\n",
    "no_iters = 2\n",
    "lr_decrease_after_li =0.8\n",
    "epochs = [100,50,50]\n",
    "wanted_testerror = 2.\n",
    "_type = 'fwd'\n",
    "act_fun = nn.ReLU\n",
    "interval_testerror = 1\n",
    "\n",
    "batch_size = 20 #200 # 60000 for full batch\n",
    "\n",
    "lr_init = 1e-1\n",
    "optimizer_type = 'SGD'\n",
    "lrscheduler_type = 'StepLR'\n",
    "lrscheduler_args = {'step_size': 10,\n",
    "                    'gamma': 0.1}\n",
    "\n",
    "\n",
    "# for classical \n",
    "epochs_classical = sum(epochs)\n",
    "lr_init_classical = lr_init\n",
    "lrscheduler_args_classical = {'step_size': 10,\n",
    "                    'gamma': 0.1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data from open datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('no of iterations in one epoch:',int(len(training_data)/batch_size))\n",
    "print(len(training_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=10000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_net ={\n",
    "        'hidden_layers': 1,\n",
    "        'dim_hidden_layers': fix_width,\n",
    "        'act_fun': act_fun,\n",
    "        'type': _type\n",
    "}\n",
    "\n",
    "dim_in = 28*28\n",
    "dim_out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classical net\n",
    "kwargs_net_classical = {\n",
    "    'hidden_layers': 3,\n",
    "    'dim_hidden_layers': fix_width,\n",
    "    'act_fun': act_fun,\n",
    "    'type': _type\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine which trainings are run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = True\n",
    "T2 = True\n",
    "T3 = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with layer insertion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "if _type=='fwd':\n",
    "    model_init = feed_forward(dim_in, dim_out,**kwargs_net)\n",
    "if _type=='res2':\n",
    "    model_init = two_weight_resnet(dim_in, dim_out,**kwargs_net)\n",
    "\n",
    "param_init = torch.nn.utils.parameters_to_vector(model_init.parameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check initial test error of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_testerror(test_dataloader,model_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train ali 1\n",
    "if T1:\n",
    "    model1, mb_losses1, test_errors_short1, test_errors1, exit_flag1 = layer_insertion_loop(\n",
    "        iters=no_iters,\n",
    "        epochs=epochs,\n",
    "        model= model_init,\n",
    "        kwargs_net=kwargs_net,\n",
    "        dim_in=dim_in,\n",
    "        dim_out=dim_out,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        lr_init=lr_init,\n",
    "        wanted_test_error=wanted_testerror,\n",
    "        mode='abs max',\n",
    "        optimizer_type=optimizer_type,\n",
    "        lrschedule_type=lrscheduler_type,\n",
    "        lrscheduler_args=lrscheduler_args,\n",
    "        check_testerror_between=interval_testerror,\n",
    "        decrease_after_li=lr_decrease_after_li,\n",
    "        print_param_flag=False,\n",
    "        start_with_backtracking=None,\n",
    "        v2=False\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_testerror(test_dataloader, model1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_list=[]\n",
    "for i,e in enumerate(epochs):\n",
    "    end_list.append(int(e*len(training_data)/batch_size))\n",
    "    end_list.append(1) \n",
    "end_list.pop() # removes last 1 which was too much\n",
    "\n",
    "# todo plot\n",
    "if T1:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.grid(which='major', axis='x', zorder=-1.0)\n",
    "    xfull = range(1,len(mb_losses1)+1)\n",
    "    yfull = mb_losses1\n",
    "    begin=0\n",
    "    end=0\n",
    "    for i in range(len(end_list)):\n",
    "        end=end+end_list[i]\n",
    "        x_curr= xfull[begin:end]\n",
    "        y_curr= yfull[begin:end]\n",
    "        begin=end\n",
    "        plt.plot(x_curr,y_curr,'o')\n",
    "    plt.xlabel('minibatch iterations')\n",
    "    plt.ylabel('minibatch loss')\n",
    "\n",
    "    plt.yscale('log')\n",
    "    #plt.ylim((0.4,.6))\n",
    "    #plt.xlim((99300,99800))\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.plot(np.zeros(len(mb_losses1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(test_errors1,'o')\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build net\n",
    "if _type=='fwd':\n",
    "    model_init2 = feed_forward(dim_in, dim_out,**kwargs_net)\n",
    "if _type=='res2':\n",
    "    model_init2 = two_weight_resnet(dim_in, dim_out,**kwargs_net)\n",
    "\n",
    "torch.nn.utils.vector_to_parameters(param_init, model_init2.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T2:\n",
    "    model2, mb_losses2, test_errors_short2, test_errors2, exit_flag2 = layer_insertion_loop(\n",
    "        iters=no_iters,\n",
    "        epochs=epochs,\n",
    "        model= model_init2,\n",
    "        kwargs_net=kwargs_net,\n",
    "        dim_in=dim_in,\n",
    "        dim_out=dim_out,\n",
    "        train_dataloader=train_dataloader,\n",
    "        test_dataloader=test_dataloader,\n",
    "        lr_init=lr_init,\n",
    "        wanted_test_error=wanted_testerror,\n",
    "        mode='abs min',\n",
    "        optimizer_type=optimizer_type,\n",
    "        lrschedule_type=lrscheduler_type,\n",
    "        lrscheduler_args=lrscheduler_args,\n",
    "        check_testerror_between=interval_testerror,\n",
    "        decrease_after_li=lr_decrease_after_li,\n",
    "        print_param_flag=False,\n",
    "        start_with_backtracking=None,\n",
    "        v2=False\n",
    "    ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo plot\n",
    "if T2:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.grid(which='major', axis='x', zorder=-1.0)\n",
    "    xfull = range(1,len(mb_losses2)+1)\n",
    "    yfull = mb_losses2\n",
    "    begin=0\n",
    "    end=0\n",
    "    for i in range(len(end_list)):\n",
    "        end=end+end_list[i]\n",
    "        x_curr= xfull[begin:end]\n",
    "        y_curr= yfull[begin:end]\n",
    "        begin=end\n",
    "        plt.plot(x_curr,y_curr,'o')\n",
    "    plt.xlabel('minibatch iterations')\n",
    "    plt.ylabel('minibatch loss')\n",
    "\n",
    "    plt.yscale('log')\n",
    "    #plt.ylim((0.4,.6))\n",
    "    #plt.xlim((99300,99800))\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.plot(np.zeros(len(mb_losses2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "#plt.ylim((0,100))\n",
    "plt.plot(test_errors2,'o')\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "if _type=='fwd':\n",
    "    model_classical = feed_forward(dim_in, dim_out,**kwargs_net_classical)\n",
    "if _type=='res2':\n",
    "    model_classical = two_weight_resnet(dim_in, dim_out,**kwargs_net_classical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build optimizer\n",
    "if optimizer_type == 'SGD':\n",
    "    optimizer_classical = torch.optim.SGD(model_classical.parameters(), lr_init_classical)\n",
    "\n",
    "# build lr scheduler\n",
    "if lrscheduler_type == 'StepLR':\n",
    "    step_size = lrscheduler_args_classical['step_size']\n",
    "    gamma = lrscheduler_args_classical['gamma']\n",
    "    lrscheduler_classical = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer_classical, step_size=step_size, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T3:\n",
    "    print('training classically on model', model_classical)\n",
    "    mblosses_classical, lr_end, test_error_classical, exit_flag_classical = train(model_classical,\n",
    "                                                             train_dataloader=train_dataloader,\n",
    "                                                             epochs=epochs_classical,\n",
    "                                                             optimizer=optimizer_classical,\n",
    "                                                             scheduler=lrscheduler_classical,\n",
    "                                                             wanted_testerror=wanted_testerror,\n",
    "                                                             start_with_backtracking=None,\n",
    "                                                             check_testerror_between=interval_testerror,\n",
    "                                                             test_dataloader=test_dataloader,\n",
    "                                                             print_param_flag=False\n",
    "                                                             )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T3:\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(mblosses_classical,'o')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    #plt.xlim((-10,3000))\n",
    "    #plt.ylim((0.68,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(test_error_classical,'o')\n",
    "plt.ylim(bottom=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the trainings as plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.zeros(max(len(mb_losses1),len(mb_losses2),len(mblosses_classical))))\n",
    "\n",
    "\n",
    "plt.plot(mb_losses2, label='ali min')\n",
    "plt.plot(mb_losses1,label='ali max')\n",
    "\n",
    "plt.plot(mblosses_classical, label='classical coarse')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "#plt.ylim((1e-8,1.1))\n",
    "#plt.xlim((99800,102000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_factor = 0.99\n",
    "s1= ema(mb_losses1, smooth_factor)\n",
    "s2= ema(mb_losses2, smooth_factor)\n",
    "s3 = ema(mblosses_classical, smooth_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(np.zeros(max(len(s1),len(s2),len(s3))))\n",
    "\n",
    "\n",
    "plt.plot(s2, label='ali min')\n",
    "plt.plot(s1,label='ali max')\n",
    "\n",
    "plt.plot(s3, label='classical coarse')\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.legend()\n",
    "#plt.ylim((1e-8,1.1))\n",
    "#plt.xlim((99800,102000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(test_errors1,'o',label='absmax')\n",
    "plt.plot(test_errors2,'o', label='absmin')\n",
    "plt.plot(test_error_classical,'o',label='comparison')\n",
    "plt.grid()\n",
    "plt.ylim(bottom=0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multilevel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
